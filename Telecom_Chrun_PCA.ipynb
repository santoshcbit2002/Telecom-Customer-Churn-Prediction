{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Class Imbalancing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression : \n",
      "-------------------------\n",
      "Classification report :  \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.99      0.97      8225\n",
      "           1       0.75      0.37      0.50       701\n",
      "\n",
      "   micro avg       0.94      0.94      0.94      8926\n",
      "   macro avg       0.85      0.68      0.73      8926\n",
      "weighted avg       0.93      0.94      0.93      8926\n",
      "\n",
      "Accuracy   Score :  0.940958996190903\n",
      "Recall Score on train Set:  0.36741767764298094\n",
      "Recall Score on test Set:  0.37375178316690444\n"
     ]
    }
   ],
   "source": [
    "# Run the Logistic Regression to understand the current data status\n",
    "logreg = LogisticRegression()\n",
    "run_algorithm(logreg,x_train,y_train,x_test,y_test,'Logistic Regression','n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_train SMOTE Mean:  0.5 \n",
      "\n",
      "Logistic Regression : \n",
      "-------------------------\n",
      "Classification report :  \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.83      0.90      8225\n",
      "           1       0.28      0.78      0.42       701\n",
      "\n",
      "   micro avg       0.83      0.83      0.83      8926\n",
      "   macro avg       0.63      0.81      0.66      8926\n",
      "weighted avg       0.92      0.83      0.86      8926\n",
      "\n",
      "Accuracy   Score :  0.8282545373067444\n",
      "Recall Score on train Set:  0.7800586510263929\n",
      "Recall Score on test Set:  0.7817403708987162\n",
      "Adaboost Classifier : \n",
      "-------------------------\n",
      "Classification report :  \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.78      0.87      8225\n",
      "           1       0.23      0.78      0.36       701\n",
      "\n",
      "   micro avg       0.78      0.78      0.78      8926\n",
      "   macro avg       0.60      0.78      0.61      8926\n",
      "weighted avg       0.92      0.78      0.83      8926\n",
      "\n",
      "Accuracy   Score :  0.7791844051086713\n",
      "Recall Score on train Set:  0.7910557184750733\n",
      "Recall Score on test Set:  0.7774607703281027\n"
     ]
    }
   ],
   "source": [
    "# Using the SMOTE techinue (Over Sampling) and run Logistic Regression \n",
    "smt = SMOTE(random_state = 100)\n",
    "x_train_smt, y_train_smt = smt.fit_sample(x_train_pca, y_train_pca)\n",
    "print('y_train SMOTE Mean: ',y_train_smt.mean(),\"\\n\")\n",
    "\n",
    "logreg = LogisticRegression()\n",
    "run_algorithm(logreg,x_train_smt,y_train_smt,x_test_pca,y_test,'Logistic Regression','n')\n",
    "\n",
    "adbc = AdaBoostClassifier(n_estimators=10,learning_rate=1)\n",
    "run_algorithm(adbc,x_train_smt,y_train_smt,x_test_pca,y_test,'Adaboost Classifier','n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_train Adaptive Over Sampling Mean:  0.5019820571667014 \n",
      "\n",
      "Logistic Regression : \n",
      "-------------------------\n",
      "Classification report :  \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.78      0.87      8225\n",
      "           1       0.25      0.87      0.39       701\n",
      "\n",
      "   micro avg       0.79      0.79      0.79      8926\n",
      "   macro avg       0.62      0.82      0.63      8926\n",
      "weighted avg       0.93      0.79      0.83      8926\n",
      "\n",
      "Accuracy   Score :  0.7862424378220928\n",
      "Recall Score on train Set:  0.8389962593516209\n",
      "Recall Score on test Set:  0.8659058487874465\n",
      "Adaboost Classifier : \n",
      "-------------------------\n",
      "Classification report :  \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.78      0.87      8225\n",
      "           1       0.23      0.78      0.35       701\n",
      "\n",
      "   micro avg       0.78      0.78      0.78      8926\n",
      "   macro avg       0.60      0.78      0.61      8926\n",
      "weighted avg       0.92      0.78      0.83      8926\n",
      "\n",
      "Accuracy   Score :  0.7776159533945777\n",
      "Recall Score on train Set:  0.7180486284289277\n",
      "Recall Score on test Set:  0.7774607703281027\n"
     ]
    }
   ],
   "source": [
    "# Apply Adaptive Over Sampling technique\n",
    "asmt = ADASYN(random_state = 100)\n",
    "x_train_asmt, y_train_asmt = asmt.fit_sample(x_train_pca, y_train_pca)\n",
    "print('y_train Adaptive Over Sampling Mean: ',y_train_asmt.mean(),\"\\n\")\n",
    "\n",
    "logreg = LogisticRegression()\n",
    "run_algorithm(logreg,x_train_asmt,y_train_asmt,x_test_pca,y_test,'Logistic Regression','n')\n",
    "\n",
    "adbc = AdaBoostClassifier(n_estimators=10,learning_rate=1)\n",
    "run_algorithm(adbc,x_train_asmt,y_train_asmt,x_test_pca,y_test,'Adaboost Classifier','n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_train Random Under Sampling Mean:  0.5 \n",
      "\n",
      "Logistic Regression : \n",
      "-------------------------\n",
      "Classification report :  \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.82      0.89      8225\n",
      "           1       0.26      0.76      0.39       701\n",
      "\n",
      "   micro avg       0.81      0.81      0.81      8926\n",
      "   macro avg       0.62      0.79      0.64      8926\n",
      "weighted avg       0.92      0.81      0.85      8926\n",
      "\n",
      "Accuracy   Score :  0.8142505041451938\n",
      "Recall Score on train Set:  0.7469670710571924\n",
      "Recall Score on test Set:  0.7631954350927247\n",
      "\n",
      "\n",
      "Adaboost Classifier : \n",
      "-------------------------\n",
      "Classification report :  \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.84      0.90      8225\n",
      "           1       0.27      0.70      0.39       701\n",
      "\n",
      "   micro avg       0.83      0.83      0.83      8926\n",
      "   macro avg       0.62      0.77      0.64      8926\n",
      "weighted avg       0.92      0.83      0.86      8926\n",
      "\n",
      "Accuracy   Score :  0.8264620210620659\n",
      "Recall Score on train Set:  0.6938186019641825\n",
      "Recall Score on test Set:  0.6990014265335235\n"
     ]
    }
   ],
   "source": [
    "# Apply Random Under Sampling Techique \n",
    "rusm=RandomUnderSampler(random_state = 100)\n",
    "x_train_rusm, y_train_rusm = rusm.fit_sample(x_train_pca, y_train_pca)\n",
    "print('y_train Random Under Sampling Mean: ',y_train_rusm.mean(),\"\\n\")\n",
    "\n",
    "logreg = LogisticRegression()\n",
    "run_algorithm(logreg,x_train_rusm,y_train_rusm,x_test_pca,y_test,'Logistic Regression','n')\n",
    "\n",
    "print(\"\\n\")\n",
    "\n",
    "adbc = AdaBoostClassifier(n_estimators=10,learning_rate=1)\n",
    "run_algorithm(adbc,x_train_rusm,y_train_rusm,x_test_pca,y_test,'Adaboost Classifier','n')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PCA "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20827, 94)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEKCAYAAAD9xUlFAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvIxREBQAAIABJREFUeJzt3Xl8XXWd//HXu2nTJd0XWugOlKUgUIhlVRkFBRFwFxAURJEZcF9+OMMPFWdGx3HDgZ9aFllGQcARCxbBUXYU20J32pIu0HRNS5ekbdKk+fz+OKfhkqbJ6XJzk9z38/G4j9xz7vec+7m3t/dzz3dVRGBmZgbQrdABmJlZx+GkYGZmTZwUzMysiZOCmZk1cVIwM7MmTgpmZtbEScHMzJo4KZiZWRMnBTMza9K90AHsraFDh8a4ceMKHYaZWacyc+bM9RExrK1ynS4pjBs3jhkzZhQ6DDOzTkXSq1nKufrIzMyaOCmYmVkTJwUzM2vipGBmZk2cFMzMrEnekoKkOyStkzRvD49L0k8lVUiaI+nEfMViZmbZ5PNK4U7gnFYePxeYkN6uAn6Wx1jMzCyDvI1TiIinJY1rpciFwN2RrAf6N0kDJR0cEavzFZNZMYkIttfvZPP2erZsb2BLbT01tQ1s27GT7fXJra5+Jzt2NlJX34iX5u343nX0cI4fPTCvz1HIwWsjgRU525Xpvt2SgqSrSK4mGDNmTLsEZ9YR1dbvpKq6jrVballXXceGmjo2bN3BhpodbNhax+tbd/D61h1s3FbP5m317NjZmPncUh4DtwPioP69unRSaOkj2OJPlYiYAkwBKC8v988Z67J2NgaVG7expKqGJeu2sqSqhlWba1m7uZa11bVs2lbf4nED+/RgcFkpQ8pKGT+0jBP7lDKwTykD+/RgQO8e9O/Vg/69u9O3Z3f6lHand48SepV2o2f3Enp270ZpSTe6dXNWsMImhUpgdM72KGBVgWIxa1cRwcpN21m0pppFa6tZvKaaV9bVsKSqhtr6N37dDykrZdSg3owZ0oe3jh/E8H69GD6gF8P792JY354M7VfK4D6ldC9xR0I7MAqZFKYC10q6DzgZ2Oz2BOuKaut3snhtNfNXbeHl1clt4epqqusamsocPKAXE4b349RDhzBheF8OP6gvhw7ty6Cy0gJGbsUob0lB0r3AmcBQSZXAN4EeABHxc2Aa8F6gAtgGXJGvWMzay7YdDSxYtYU5lZuZt3Iz81ZtZknVVnY2JrWefXt256gR/Xj/pJEcOaIfR43oxxEj+tG/V48CR26WyGfvo4vbeDyAa/L1/Gb51tgYVFTV8OKrG5m1YhOzVmxi8dpq0u9/DurXk2NHDuA9x4zgmEP6c/TB/Rk9qI/r7q1D63RTZ5sVSm39Tmav2MT05a8zfflGXnxtI9W1SRXQwD49OG7UQN49cTjHjRrIW0YNYHj/XgWO2GzvOSmY7cGOhkZmrdjE80vW89clG3jptU1NXTyPGN6X9x13CCeNHcSJYwYyfmgZcp9O6wKcFMxSEcHitTU880oVz1as54Wlr7O9ficSHHvIAC4/fRyTxw2mfNwgBvZxA7B1TU4KVtS27Wjg2VfW88SiKp5ctI7Vm2sBOHRYGR8pH8Xphw/llPFDGNDHDcFWHJwUrOhUVdfx55fX8qcFa3m2Yj11DY307dmdMw4fyhfeNYy3HTGMkQN7FzpMs4JwUrCi8NqGbTw2fw2PzV/DzNc2EgGjBvXmkpPHcPbRwykfN5jS7h4AZuakYF3W4rXV/HHeGh6dt4aXV28BYOLB/fnCuybw7okjOPrgfm4cNmvGScG6lMVrq3lkzmqmzV1NxboaJCgfO4jrzzua9xwzgtGD+xQ6RLMOzUnBOr0lVTU8Mns1j8xZxStpIjh5/GA+eeoxvOeYERzk8QJmmTkpWKe0eXs9D89exf0zVjCncjMSvHXsYG688BjOOXYEB/VzIjDbF04K1qnMWrGJu/+6nD/MWU1dQyNHjejH9ecdzfuOO4QRA5wIzPaXk4J1eLX1O/nDnNXc/dflzK7cTFlpCR8+aRQfe+to3jJygBuLzQ4gJwXrsFZv3s5//+1V7v37Cl7fuoPDD+rLjRcewwcmjaSfZxU1ywsnBetwFq7Zws+eXMIjc1bTGMFZRw/n8tPGcdphQ3xVYJZnTgrWYcx89XVueWIJf1m4jrLSEq44bRyfPG2cu5GatSMnBSu4vy3dwE///ArPL9nA4LJSvnL2EVx26lhPOmdWAHlNCpLOAW4CSoDbIuJ7zR4fC9wBDANeBy6NiMp8xmQdx9+WbuBHf1rM35e9zrB+Pbn+vKO55OQx9Cn1bxWzQsn0v0/SGcCEiPilpGFA34hY1sYxJcAtwNlAJTBd0tSIWJBT7AfA3RFxl6R3At8FLtuXF2Kdx4uvbeRHjy/m2Yr1HNSvJ988fyIXTx5Drx4lhQ7NrOi1mRQkfRMoB44EfkmyzvJ/A6e3cehkoCIilqbnuQ+4EMhNChOBL6X3nwAe2pvgrXOp3LiN705byB/mrmZIWSnXn3c0l54y1snArAPJcqXwAWAS8CJARKyS1C/DcSOBFTnblcDJzcrMBj5EUsX0AaCfpCERsSHD+a2T2LajgZ8/uYRfPL0UCb541gQ+87ZDKevpaiKzjibL/8odERGSAkBSWcZzt9R3MJptfxW4WdLlwNPASqBhtxNJVwFXAYwZMybj01uhRQR/nLeG7zyygFWba7ng+EO47tyjOMRrFZh1WFmSwv2SfgEMlPQZ4FPArRmOqwRG52yPAlblFoiIVcAHAST1BT4UEZubnygipgBTAMrLy5snFuuAllbV8M2p83nmlfUcNaIfN108ibeOG1zosMysDW0mhYj4gaSzgS0k7Qo3RMSfMpx7OjBB0niSK4CLgEtyC0gaCrweEY3AN0h6Ilkntn3HTm5+4hWmPL2UXt1L+Nb5E7n0lLF0L/ECNmadQZaG5vHAM7sSgaTeksZFxPLWjouIBknXAo+RdEm9IyLmS7oRmBERU4Ezge+mVVNPA9fs16uxgokI/rRgLd9+eAErN23ng5NGct17j/JspWadjCJar42RNAM4LSJ2pNulwHMR8dZ2iG835eXlMWPGjEI8te3Bite38a2p8/nzwnUcMbwv37nwWE4+dEihwzKzHJJmRkR5W+WytCl035UQACJiR5oYrMjV72zk1meW8tM/v0I3iX9+71Fccfp4eriqyKzTypIUqiRdkFb3IOlCYH1+w7KObm7lZr724GwWrqnmnGNGcMP5E92ryKwLyJIUrgZ+Jelmkm6mK4BP5DUq67Bq63fyk/99hVufWcqQslJu/UQ5Z08cXuiwzOwAydL7aAlwStplVBFRnf+wrCOa+epGvvbgbJZWbeVj5aP55/OOZkBvr2tg1pVk6X3Uk2TU8Tig+6757CPixrxGZh3G9h07+eHji7j9uWUcMqA391w5mbdNGFbosMwsD7JUH/0e2AzMBOryG451NPNWbubz977E0vVb+fjJY/jGe4+mr6enMOuysvzvHhUR5+Q9EutQGhuD259dxvcfW8iQsp786tMnc/rhQwsdlpnlWZak8Lykt0TE3LxHYx1CVXUdX75/Fs+8sp53TxzOf3zoOAaVuReyWTHIkhTOAC6XtIyk+khARMRxeY3MCuL5Jev5wn2z2LK9nn99/7F8/OQxXhfZrIhkSQrn5j0KK7idjcHNf6ngpj8vZvzQMu65cjJHjehf6LDMrJ1l6ZL6KoCkgwBPZNMFVdfW8/l7X+KJRVV8cNJIvvP+Y73WgVmRytIl9QLgh8AhwDpgLPAycEx+Q7P28NqGbVx513SWrd/q6iIzy1R99B3gFOB/I2KSpH8ALs5vWNYeXli6gav/eyaNAXdfOZnTDnPvIrNil2Xmsvp0ecxukrpFxBPACXmOy/LstzMrufT2FxhUVspD15zuhGBmQLYrhU3pFBdPk8yBtI4Wlsy0ziEi+NGfFvNff6ngtMOG8LOPn8SAPp6qwswSWZLChUAt8CXg48AAwFNcdEJ1DTv52gNzmDp7FR8rH82/fuBYT3NtZm+SpffR1pzNu/bm5JLOAW4iWXnttoj4XrPHx6TnHJiWuS4ipu3Nc1g2W+sa+Ow9M3m2Yj1fP+dI/vEdh7lB2cx2s8ekIOnZiDhDUjWQuzzbrsFrrXZil1QC3AKcDVQC0yVNjYgFOcWuB+6PiJ9JmghMI5l4zw6g17fu4Io7pzNv5WZ+8JHj+fBJowodkpl1UHtMChFxRvq33z6eezJQERFLASTdR1IVlZsUAtiVXAYAq/bxuWwPVm3azmW3v8CKjdv5+aUnee0DM2tVq9VHkroBcyLi2H0490iSBXl2qQROblbmW8Djkj4HlAFn7cPz2B4sqarhstteoLq2gbs/NZlTvG6ymbWh1VbGiGgEZqd1/3urpQrraLZ9MXBnRIwC3gvckyaiN59IukrSDEkzqqqq9iGU4jNv5WY++vO/UtfQyL1XneKEYGaZZOl9dDAwX9LfgaZG54i4oI3jKoHROduj2L166ErgnPR8f5XUCxhKMnK6SURMAaYAlJeXN08s1swLSzdw5V0zGNC7B/dcOZlDh/UtdEhm1klkSQrf3sdzTwcmSBoPrAQuAi5pVuY14F3AnZKOJplbyZcC++GJReu4+p6ZjBrUm//+9MkcPKB3oUMys04kS5fUp/blxBHRIOla4DGS7qZ3RMR8STcCMyJiKvAV4FZJXyKpWro8InwlsI+mzV3NF+57iSOG9+PuT01mSN+ehQ7JzDqZLBPinQL8F3A0UEryBb+1rS6pAOmYg2nN9t2Qc38BcPpexmwteHBmJV9/cDYnjhnE7Ze/lQG9PUrZzPZeluGsN5M0CL8C9AY+ne6zDuJXL7zKVx+YzWmHDeXuKyc7IZjZPss0aX5EVEgqiYidwC8lPZ/nuCyjXz63jG8/vIB3HnUQ/+/jJ9KrR0mhQzKzTixLUtgmqRSYJen7wGqSMQVWYL94agnffXQh7zlmOP918YmUdvc8Rma2f7J8i1yWlruWpEvqaOBD+QzK2nb7s8v47qMLOf/4Q7j5EicEMzswslwpnAhMi4gt7Hv3VDuA7vv7a3znkQWce+wIfvzR4+numU7N7ADJ8m1yAbBY0j2SzpPkxXsL6PezVvKN383lzCOHcdNFk5wQzOyAavMbJSKuAA4HHiAZfLZE0m35Dsx29+SidXz5/tlMHjeYn196kquMzOyAy9r7qF7SoyQDzHqTzHb66XwGZm+2aE011/76JY4c3o/bL3+rexmZWV60+VNT0jmS7gQqgA8Dt5HMh2TtpKq6jk/dOZ0+pSXcfnk5fXu6Bs/M8iPLt8vlwH3AZyOiLr/hWHO19Tu56p4ZbNhax/2fPdVzGZlZXmWZ++ii9gjEdhcRXPfbObz02iZ+9vETOW7UwEKHZGZdnFsqO7DbnlnGQ7NW8ZWzj+Dct7jGzszyz0mhg3p6cRXfffRlzj12BNe+8/BCh2NmRcJJoQN6dcNWPnfvS0w4qB8/+MjxSC0tYmdmduDtsU1B0lx2Xz6zSUQcl5eIity2HQ1cdfdMAKZ84iTK3NPIzNpRa98470v/XpP+vSf9+3FgW94iKmIRwf/57VwWr6vmrismM3aI5x00s/a1x+qjiHg1Il4FTo+Ir0fE3PR2HfCeLCdPxzgsklQh6boWHv+xpFnpbbGkTfv+Ujq/O55bzsOzV/HVdx/J248YVuhwzKwIZambKJN0RkQ8CyDpNDJMnS2pBLgFOBuoBKZLmpqutgZARHwpp/zngEl7GX+X8cLSDfz7tJc5e+Jw/vEdhxU6HDMrUlmSwpXAHZIGkLQxbAY+leG4yUBFRCwFkHQfyfQYC/ZQ/mLgmxnO2+Ws3VLLNb9+ibGD+/DDjx5Pt25uWDazwsgyeG0mcLyk/oAiYnPGc48EVuRsVwInt1RQ0lhgPPCXjOfuMup3NnLtr19ka10Dv/7MyfTv5aU0zaxwssx9NFzS7cBvImKzpImSrsxw7pZ+7u6pN9NFwIPpcp8txXCVpBmSZlRVVWV46s7j+39cyPTlG/neh97CEcP7FTocMytyWcYp3Ak8BhySbi8GvpjhuEqSVdp2GQWs2kPZi4B793SiiJgSEeURUT5sWNdpgP3jvNXc+swyLjtlLBeeMLLQ4ZiZZUoKQyPifqARICIagBZ/0TczHZggaXy6xvNFwNTmhSQdCQwC/po56i5g2fqtfO2BORw/eiDXv+/oQodjZgZkSwpbJQ0hrfqRdApJY3Or0uRxLclVxsvA/RExX9KNki7IKXoxcF9E7HGgXFdT17CTz937IiUl4pZLJtGzu9dGMLOOIUvvoy+T/MI/TNJzwDCSdRXaFBHTgGnN9t3QbPtbmSLtQn7w2CLmrdzClMtOYtSgPoUOx8ysSZbeRy9KegdwJEnj8aKIqM97ZF3Uk4vWNbUjvPuYEYUOx8zsTbJOrDMZGJeWP1ESEXF33qLqoqqq6/jqA7M5cng//uU8tyOYWcfTZlKQdA9wGDCLNxqYA3BS2AvJvEZzqK5t4NefOcVrLJtZh5TlSqEcmFhMDcH58PtZq/jLwnX83/dN9HgEM+uwsvQ+mge48ns/bKip49sPz+eE0QO5/LRxhQ7HzGyPslwpDAUWSPo7ULdrZ0RcsOdDLNeNjyygpq6B73/4OEo8r5GZdWBZksK38h1EV/aXhWv5/axVfPGsCa42MrMOL0uX1KfaI5CuaNuOBq7/3TyOGN6XfzrT6yybWcfX2nKcz0bEGZKqefNEdgIiIvrnPbpO7mdPLmHV5loevPhUSrt7OWwz6/j2mBQi4oz0r+s89sFrG7bxi6eXcuEJh1A+bnChwzEzyyTzqvCSDgJ67dqOiNfyElEX8W/TFlAicd25RxU6FDOzzLKsp3CBpFeAZcBTwHLg0TzH1ak9V7Gex+av5Zp/OIyDB/QudDhmZpllqej+DnAKsDgixgPvAp7La1SdWMPORr798HxGD+7Np992aKHDMTPbK1mSQn1EbAC6SeoWEU8AJ+Q5rk7r3ukrWLy2hn9570RPZWFmnU6WNoVNkvoCTwO/krQOaMhvWJ1TTV0DN/3vYiaPH8x7jhle6HDMzPZaliuFC4HtwJeAPwJLgPPzGVRnNeWpJayv2cE/v/doJI9cNrPOJ8vgta05m3flMZZObe2WWm59ZhnnHXcwJ4weWOhwzMz2yR6vFCRVS9qSc6vO/Zvl5JLOkbRIUoWk6/ZQ5qOSFkiaL+nX+/pCCu0n/7uYhsZGvv6eIwsdipnZPmtt8Np+DVqTVALcApwNVALTJU2NiAU5ZSYA3wBOj4iN6ViITmfx2mp+M30FnzxtHGOHlBU6HDOzfZZp8JqkE4EzSKa7eDYiXspw2GSgIiKWpue4j6R9YkFOmc8At0TERoCIWLcXsXcYP3p8MWWl3fncOycUOhQzs/2SZfDaDSRtCUNIptG+U9L1Gc49EliRs12Z7st1BHCEpOck/U3SOXuI4SpJMyTNqKqqyvDU7Wfx2mr+OH8Nl58+jsFlpYUOx8xsv2S5UrgYmBQRtQCSvge8CPxrG8e11P2m+ept3YEJwJnAKOAZScdGxKY3HRQxBZgCUF5e3qFWgLv5LxWUlZbwqdPHFzoUM7P9lqVL6nJy5jwCepJ0S21LJTA6Z3sUsKqFMr+PiPqIWAYsIkkSncLSqhoembOKS08dyyBfJZhZF5AlKdQB8yXdKemXJMtz1kj6qaSftnLcdGCCpPGSSoGLgKnNyjwE/AOApKEk1UlL9/ZFFMotTyyhtHs3PuPpLMysi8hSffS79LbLk1lOHBENkq4FHgNKgDsiYr6kG4EZETE1fezdkhYAO4GvpVNqdHivbdjGQ7NW8slTxzG0b89Ch2NmdkBkSQqPNu8VJOnIiFjU1oERMQ2Y1mzfDTn3A/hyeutUfvbUEkq6ic++w1cJZtZ1ZKk+ekbSR3dtSPoKb75yKDobaur47YuVfPikUQzv36vtA8zMOoksVwpnAlMkfQQYDrxMMgahaP36hdfY0dDoHkdm1uW0eaUQEatJJsI7FRgH3B0RNXmOq8Pa0dDI3X97lXccMYzDD+pb6HDMzA6oNq8UJP0JWA0cS9Kt9A5JT0fEV/MdXEf0h7mrqKqu44oPjyt0KGZmB1yWNoVbIuITEbEpIuYBpwGb8xxXhxQR/PK55Rw2rIy3TxhW6HDMzA64LNVHD0kaK+msdFcP4Cf5DatjmvnqRuZUbuby08fTrZvXSzCzrifL3EefAR4EfpHuGkUy6Kzo/PK55fTv1Z0Pndh8Ciczs64hS/XRNcDpwBaAiHgF6JRTXO+PNZtr+eP8NVw0eQx9SjNNLmtm1ulkmuYiInbs2pDUnd0ntuvyfvtiJTsbg0smjyl0KGZmeZMlKTwl6Z+B3pLOBh4AHs5vWB1LRHD/jBWcPH4w44Z6ER0z67qyJIXrgCpgLvBZkmkrsqyn0GX8fdnrvLphGx8tH912YTOzTqzNyvGIaARuTW9F6f4ZlfTt2Z1z3zKi0KGYmeVVliuFolZdW8+0uas5//hD3MBsZl2ek0Ib/jBnNdvrd/LR8lGFDsXMLO8yJwVJRdnC+psZK5hwUF9OGD2w0KGYmeVdlsFrp6WL4Lycbh8v6f/lPbIOoGJdNS+9tomPlo9G8ghmM+v6slwp/Bh4D7ABICJmA2/PcnJJ50haJKlC0nUtPH65pCpJs9Lbp/cm+Hz7nxdXUtJNvH+SRzCbWXHI1HIaESua/VLe2dYxkkqAW4CzgUpguqSpEbGgWdHfRMS1GeNtNxHBw3NWcdphQxjWz8ttmllxyHKlsELSaUBIKpX0VdKqpDZMBioiYmk6Ivo+4ML9iLVdzVqxiRWvb+eC4w8pdChmZu0mS1K4mmT+o5Ekv/hPSLfbMhJYkbNdme5r7kOS5kh6UFKHGR02dfYqSku68e5jPDbBzIpHluojRcTH9+HcLbXMNp8z6WHg3oiok3Q1cBfwzt1OJF0FXAUwZkz+5x7a2Rj8Yc5qzjxyGAN698j785mZdRRZrhSel/S4pCsl7U2/zEog95f/KGBVboGI2BARdenmrcBJLZ0oIqZERHlElA8blv/FbV5YtoF11XVccIKrjsysuGRZZGcCyVxHxwAvSnpE0qUZzj0dmCBpvKRS4CJgam4BSQfnbF5AtraKvHt49mr6lJbwrqOGFzoUM7N2lWnwWkT8PSK+TNJ4/DpJNU9bxzQA1wKPkXzZ3x8R8yXdKOmCtNjnJc2XNBv4PHD5PryGA2pHQyOPzlvN2ROH07u0pNDhmJm1qzbbFCT1Bz5A8kv/MOB3JMmhTRExjWRW1dx9N+Tc/wbwjb2IN++erahi07Z6zj/OVUdmVnyyNDTPJll+88aI+Gue4ym4P85bQ/9e3Xn7EflvuzAz62iyJIVDI6JoVlqbt3ILJ4wZRGl3zxVoZsVnj0lB0k8i4ovAVEm7JYWIuKCFwzq1hp2NVKyr4YwJQwsdiplZQbR2pXBP+vcH7RFIR7Bs/VZ27GzkqBH9Ch2KmVlB7DEpRMTM9O4JEXFT7mOSvgA8lc/ACuHlNdUAHDWif4EjMTMrjCwV559sYd/lBziODmHRmi2UdBOHHVSUS0eYmbXapnAxcAkwXlLuoLN+pNNodzULV1dz2LAyenb3+AQzK06ttSk8D6wGhgI/zNlfDczJZ1CFsnBNNSeNHVToMMzMCqa1NoVXgVeBU9svnMLZUlvPyk3bueTk/E+4Z2bWUWVZjvMUSdMl1UjaIWmnpC3tEVx7WpQ2Mh99sHsemVnxytLQfDNwMfAK0Bv4NPBf+QyqEBauTvKcex6ZWTHLuhxnhaSSiNgJ/FLS83mOq90tXFNNv17dOXhAr0KHYmZWMFmSwrZ06utZkr5P0vjc5fpsLlxTzdEj+tNsLWozs6KSpfroMqCEZBrsrSQL53won0G1t4hg0ZpqjnJ7gpkVuTavFNJeSADbgW/nN5zCqNy4nZq6Bo709BZmVuRaG7w2l93XVG4SEcflJaICWOjpLczMgNavFN63vyeXdA5wE0n1020R8b09lPsw8ADw1oiYsb/Pu7cWrUl6HvlKwcyKXVuD1/aZpBLgFuBsoBKYLmlqRCxoVq4fyVKcL+zP8+2Pl9dUM3pwb/r2zNQZy8ysy8oyeK1a0pb0VrsXg9cmAxURsTQidgD3ARe2UO47wPeB2r2K/ABauHqLq47MzMiQFCKiX0T0T2+9SHoe3Zzh3COBFTnblem+JpImAaMj4pG9iPmA2tHQyPIN2zhieN9ChWBm1mHs9ZqTEfEQ8M4MRVvq8N/UcC2pG/Bj4Cttnki6StIMSTOqqqoyx5rF8g1b2dkYTDjI7QlmZm1Wokv6YM5mN6CcVnol5agkGdOwyyhgVc52P+BY4Ml0wNgIkqU/L2je2BwRU4ApAOXl5Qd0veiKdTUAHH6QrxTMzLK0rJ6fc78BWE7LbQPNTQcmSBoPrAQuIlmfAYCI2EwyLTcAkp4EvtrevY92JYVDh3W5QdpmZnsty+C1K/blxBHRIOla4DGSLql3RMR8STcCMyJiautnaB8V62oYObA3fUrd88jMLEv10Xjgc8C43PIRcUFbx0bENGBas3037KHsmW2dLx8q1tW46sjMLJXl5/FDwO3Aw0BjfsNpX42NwdL1NZx62JBCh2Jm1iFkSQq1EfHTvEdSACs3bae2vtFXCmZmqSxJ4SZJ3wQeB+p27YyIF/MWVTtxzyMzszfLkhTeQjJ99jt5o/ooyDZWoUNrSgrDnBTMzCBbUvgAcGg6VUWX8sq6aob2LWVQWWmhQzEz6xCyjGieDQzMdyCFULGuhsN8lWBm1iTLlcJwYKGk6by5TaHNLqkdWURQsa6G848/pNChmJl1GFmSwjfzHkUBVNXUsaW2wY3MZmY5soxofqo9Amlv7nlkZra7LCOaq3ljArxSoAewNSI69QIES5wUzMx2k+VK4U1zSkt6P8kCOp1axboa+vbszoj+vQodiplZh5HP9RQ6tIqqGg4bVkY6bbeZmZHf9RQ6tIp1NZx++NC2C5qZFZF8rqfQYW2prWftljqvtmZm1kze1lPoyJav3wp4YR0zs+babFOQdJekgTnbgySWE9EeAAALe0lEQVTdkd+w8qty43YARg/qU+BIzMw6liwNzcdFxKZdGxGxEZiU5eSSzpG0SFKFpOtaePxqSXMlzZL0rKSJ2UPfd5UbtwEwclDv9ng6M7NOI0tS6CZp0K4NSYPJ1kBdAtwCnAtMBC5u4Uv/1xHxlog4Afg+8KPMke+Hyo3b6d+rOwN692iPpzMz6zSyNDT/EHhe0oMkvY4+CvxbhuMmAxURsRRA0n0kDdQLdhWIiC055ctop15NKzduZ6SrjszMdpOlofluSTNIxiYI+GBELGjjMICRwIqc7Urg5OaFJF0DfJlktHS7jH+o3LidMUOcFMzMmstypUCaBLIkglwtjQrb7UogIm4BbpF0CXA98MndTiRdBVwFMGbMmL0MY7fnY+Wm7V6X2cysBXs9onkvVAKjc7ZHAataKX8f8P6WHoiIKRFRHhHlw4YN26+gNm+vp6augVFuZDYz200+k8J0YIKk8ZJKgYuAqbkFJE3I2TwPeCWP8QBvdEd1UjAz212m6qN9ERENkq4FHgNKgDsiYr6kG4EZETEVuFbSWUA9sJEWqo4OtDeSgtsUzMyay1tSAIiIacC0ZvtuyLn/hXw+f0t2jVHwlYKZ2e7yWX3UIa3ctJ2y0hKPUTAza0HRJYXKjdsZNaiPp8w2M2tB0SWFZOCaq47MzFpSdEmhcuM2tyeYme1BUSWFLbX1bKltYORAJwUzs5YUVVJY6e6oZmatKqqk4IFrZmatK6qksNLrKJiZtaqokkLlxu306tGNIWWlhQ7FzKxDKqqksHLTdkYO7O0xCmZme1BUSWHXwDUzM2tZkSWFbW5PMDNrRdEkha11DWzcVu+eR2ZmrSiapLByk8comJm1pXiSQjpGwaOZzcz2rGiSwq51FEa7+sjMbI+KJikM79+LsycOZ2jfnoUOxcysw8prUpB0jqRFkiokXdfC41+WtEDSHEl/ljQ2X7G8+5gR3PqJcrp18xgFM7M9yVtSkFQC3AKcC0wELpY0sVmxl4DyiDgOeBD4fr7iMTOztuXzSmEyUBERSyNiB3AfcGFugYh4IiK2pZt/A0blMR4zM2tDPpPCSGBFznZlum9PrgQebekBSVdJmiFpRlVV1QEM0czMcuUzKbRUeR8tFpQuBcqB/2zp8YiYEhHlEVE+bNiwAxiimZnl6p7Hc1cCo3O2RwGrmheSdBbwL8A7IqIuj/GYmVkb8nmlMB2YIGm8pFLgImBqbgFJk4BfABdExLo8xmJmZhnkLSlERANwLfAY8DJwf0TMl3SjpAvSYv8J9AUekDRL0tQ9nM7MzNpBPquPiIhpwLRm+27IuX9WPp/fzMz2jiJabPvtsCRVAa/u4+FDgfUHMJzOyu+D34Nd/D4Uz3swNiLa7KnT6ZLC/pA0IyLKCx1Hofl98Huwi98HvwfNFc3cR2Zm1jYnBTMza1JsSWFKoQPoIPw++D3Yxe+D34M3Kao2BTMza12xXSmYmVkriiYptLW2Q1ckabSkJyS9LGm+pC+k+wdL+pOkV9K/gwoda75JKpH0kqRH0u3xkl5I34PfpKPuuzRJAyU9KGlh+pk4tdg+C5K+lP5fmCfpXkm9ivGz0JqiSAoZ13boihqAr0TE0cApwDXp674O+HNETAD+nG53dV8gGVm/y38AP07fg40ks/R2dTcBf4yIo4DjSd6PovksSBoJfJ5kDZdjgRKS6XeK8bOwR0WRFMiwtkNXFBGrI+LF9H41yZfASJLXflda7C7g/YWJsH1IGgWcB9yWbgt4J8nCTlAc70F/4O3A7QARsSMiNlFknwWSWRx6S+oO9AFWU2SfhbYUS1LY27UduhxJ44BJwAvA8IhYDUniAA4qXGTt4ifA14HGdHsIsCmdnwuK4/NwKFAF/DKtRrtNUhlF9FmIiJXAD4DXSJLBZmAmxfdZaFWxJIXMazt0RZL6Ar8FvhgRWwodT3uS9D5gXUTMzN3dQtGu/nnoDpwI/CwiJgFb6cJVRS1J20suBMYDhwBlJFXKzXX1z0KriiUpZFrboSuS1IMkIfwqIv4n3b1W0sHp4wcDXXna8tOBCyQtJ6k2fCfJlcPAtAoBiuPzUAlURsQL6faDJEmimD4LZwHLIqIqIuqB/wFOo/g+C60qlqTQ5toOXVFad3478HJE/CjnoanAJ9P7nwR+396xtZeI+EZEjIqIcST/7n+JiI8DTwAfTot16fcAICLWACskHZnuehewgCL6LJBUG50iqU/6f2PXe1BUn4W2FM3gNUnvJfmFWALcERH/VuCQ8k7SGcAzwFzeqE//Z5J2hfuBMST/UT4SEa8XJMh2JOlM4KsR8T5Jh5JcOQwGXgIu7eor/0k6gaSxvRRYClxB8sOwaD4Lkr4NfIykZ95LwKdJ2hCK6rPQmqJJCmZm1rZiqT4yM7MMnBTMzKyJk4KZmTVxUjAzsyZOCmZm1sRJwTo1SU9Kyvv6upI+n84s+qt8P1chpTOp/lOh47DCcVKwopUzijWLfwLemw5868oGkrxWK1JOCpZ3ksalv7JvTeeyf1xS7/Sxpl/6koam01Eg6XJJD0l6WNIySddK+nI6mdvfJA3OeYpLJT2fzpE/OT2+TNIdkqanx1yYc94HJD0MPN5CrF9OzzNP0hfTfT8nmVBuqqQvNStfIukHkuZKmiPpc+n+d6XPOzeNo2e6f7mkf5f0V0kzJJ0o6TFJSyRdnZY5U9LTkn4naYGkn0vqlj52cXrOeZL+IyeOGkn/Jml2+v4MT/cPk/Tb9H2YLun0dP+30rielLRU0ufTU30POEzSLEn/KengNJZZ6XO+bZ8/CNY5RIRvvuX1BowjGUF6Qrp9P8moUYAnSea3BxgKLE/vXw5UAP2AYSQzWl6dPvZjksn9dh1/a3r/7cC89P6/5zzHQGAxyQRol5PMAzS4hThPIhn9XQb0BeYDk9LHlgNDWzjmH0nmluqebg8GepHMyntEuu/unHiXA/+Y8zrm5LzGden+M4FakkRUAvyJZBqGQ0hGHQ8jmeDuL8D702MCOD+9/33g+vT+r4Ez0vtjSKY8AfgW8DzQM33fNwA90n+reTmv7yvAv6T3S4B+hf48+Zbf295cPpvtj2URMSu9P5Pky6ctT0SyDkS1pM3Aw+n+ucBxOeXuBYiIpyX1lzQQeDfJRHhfTcv0IvlSBPhTtDyVwxnA7yJiK4Ck/wHeRjL1wZ6cBfw80qmXI+J1Scenr3dxWuYu4BqSaVbgjXm35gJ9c15jbRo7wN8jYmkax71pbPXAkxFRle7/FUkifAjYATySHjsTODsnvonJVD8A9JfUL73/h0imc6iTtA4Y3sLrmw7coWRixYdy/g2ti3JSsPaSO5fMTqB3er+BN6oxe7VyTGPOdiNv/uw2n6slSKbH/lBELMp9QNLJJNNGt6SlKbXbohaev63z5L6O5q9x1+va02vak/qI2HXMzpzzdANOjYjtbwowSRLN/012+z5IE+3bSRYpukfSf0bE3a3EYZ2c2xSs0JaTVNvAGzNV7q2PQdMEgJsjYjPwGPC5dDZMJE3KcJ6ngfens2iWAR8gmVCwNY8DV+9qtE7bOhYC4yQdnpa5DHhqL1/TZCWz+nYjeX3Pkkxk+I607aUEuDjDeR8Hrt21kU6K15pqkuqsXeXHklRr3Uoy4+6Je/k6rJPxlYIV2g+A+yVdRlJHvi82Snoe6A98Kt33HZLqmjlpYlgOvK+1k0TEi5LuBP6e7rotIlqrOoJk1tEj0uepJ2nfuFnSFcADabKYDvx8L1/TX0kafd9Ckqx+FxGNkr5BMtWzgGkR0dY0z58HbpE0h+T/+9PA1XsqHBEbJD0naR7wKDAP+Fr62mqAT+zl67BOxrOkmnUwypniu9CxWPFx9ZGZmTXxlYKZmTXxlYKZmTVxUjAzsyZOCmZm1sRJwczMmjgpmJlZEycFMzNr8v8Bmbh/oTr4s80AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8926, 50)\n",
      "(20827, 50)\n",
      "Logistic Regression : \n",
      "-------------------------\n",
      "Classification report :  \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.99      0.97      8225\n",
      "           1       0.73      0.37      0.49       701\n",
      "\n",
      "   micro avg       0.94      0.94      0.94      8926\n",
      "   macro avg       0.84      0.68      0.73      8926\n",
      "weighted avg       0.93      0.94      0.93      8926\n",
      "\n",
      "Accuracy   Score :  0.9398386735379789\n",
      "Recall Score on train Set:  0.35239745811669554\n",
      "Recall Score on test Set:  0.37089871611982883\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression : \n",
      "-------------------------\n",
      "Classification report :  \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.75      0.85      8225\n",
      "           1       0.22      0.82      0.34       701\n",
      "\n",
      "   micro avg       0.75      0.75      0.75      8926\n",
      "   macro avg       0.60      0.78      0.59      8926\n",
      "weighted avg       0.92      0.75      0.81      8926\n",
      "\n",
      "Accuracy   Score :  0.7514004033161551\n",
      "Recall Score on train Set:  0.7313534822601839\n",
      "Recall Score on test Set:  0.818830242510699\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best recall: 0.7342, with best C: {'C': 20}\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression with C : \n",
      "-------------------------\n",
      "Classification report :  \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.77      0.87      8293\n",
      "           1       0.23      0.83      0.36       692\n",
      "\n",
      "   micro avg       0.78      0.78      0.78      8985\n",
      "   macro avg       0.61      0.80      0.62      8985\n",
      "weighted avg       0.92      0.78      0.83      8985\n",
      "\n",
      "Accuracy   Score :  0.7784084585420145\n",
      "Recall Score on train Set:  0.7323059360730594\n",
      "Recall Score on test Set:  0.8251445086705202\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Balanced Weight : \n",
      "-------------------------\n",
      "Classification report :  \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.78      0.87      8293\n",
      "           1       0.23      0.82      0.36       692\n",
      "\n",
      "   micro avg       0.78      0.78      0.78      8985\n",
      "   macro avg       0.61      0.80      0.62      8985\n",
      "weighted avg       0.92      0.78      0.83      8985\n",
      "\n",
      "Accuracy   Score :  0.7790762381747357\n",
      "Recall Score on train Set:  0.7320983810709838\n",
      "Recall Score on test Set:  0.8236994219653179\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RandomForest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Classifier : \n",
      "-------------------------\n",
      "Classification report :  \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.94      0.95      8225\n",
      "           1       0.45      0.55      0.49       701\n",
      "\n",
      "   micro avg       0.91      0.91      0.91      8926\n",
      "   macro avg       0.70      0.75      0.72      8926\n",
      "weighted avg       0.92      0.91      0.92      8926\n",
      "\n",
      "Accuracy   Score :  0.9109343490925387\n",
      "Recall Score on train Set:  0.999116791354946\n",
      "Recall Score on test Set:  0.5534950071326676\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[37, 33, 37, 37, 42, 37, 34, 43, 53, 39]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise-deprecating',\n",
       "       estimator=RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators='warn', n_jobs=None,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False),\n",
       "       fit_params=None, iid='warn', n_jobs=None,\n",
       "       param_grid={'max_depth': range(10, 53, 3)}, pre_dispatch='2*n_jobs',\n",
       "       refit=True, return_train_score='warn', scoring='recall', verbose=0)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_train_score</th>\n",
       "      <th>split1_train_score</th>\n",
       "      <th>split2_train_score</th>\n",
       "      <th>split3_train_score</th>\n",
       "      <th>split4_train_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.91</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>10</td>\n",
       "      <td>{'max_depth': 10}</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.03</td>\n",
       "      <td>15</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.06</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>13</td>\n",
       "      <td>{'max_depth': 13}</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.03</td>\n",
       "      <td>3</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.18</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>16</td>\n",
       "      <td>{'max_depth': 16}</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.03</td>\n",
       "      <td>2</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.26</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>19</td>\n",
       "      <td>{'max_depth': 19}</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.03</td>\n",
       "      <td>1</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.31</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>22</td>\n",
       "      <td>{'max_depth': 22}</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.03</td>\n",
       "      <td>4</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.32</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>25</td>\n",
       "      <td>{'max_depth': 25}</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.03</td>\n",
       "      <td>6</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.34</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>28</td>\n",
       "      <td>{'max_depth': 28}</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.03</td>\n",
       "      <td>5</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1.36</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>31</td>\n",
       "      <td>{'max_depth': 31}</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.03</td>\n",
       "      <td>7</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1.36</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>34</td>\n",
       "      <td>{'max_depth': 34}</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.03</td>\n",
       "      <td>8</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1.36</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>37</td>\n",
       "      <td>{'max_depth': 37}</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.03</td>\n",
       "      <td>11</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1.38</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>40</td>\n",
       "      <td>{'max_depth': 40}</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.04</td>\n",
       "      <td>10</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1.37</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>43</td>\n",
       "      <td>{'max_depth': 43}</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.03</td>\n",
       "      <td>14</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1.36</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>46</td>\n",
       "      <td>{'max_depth': 46}</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.03</td>\n",
       "      <td>13</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1.34</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>49</td>\n",
       "      <td>{'max_depth': 49}</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.03</td>\n",
       "      <td>9</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1.36</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>52</td>\n",
       "      <td>{'max_depth': 52}</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.03</td>\n",
       "      <td>12</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0            0.91          0.02             0.01            0.00   \n",
       "1            1.06          0.01             0.01            0.00   \n",
       "2            1.18          0.01             0.01            0.00   \n",
       "3            1.26          0.01             0.01            0.00   \n",
       "4            1.31          0.01             0.01            0.00   \n",
       "5            1.32          0.01             0.01            0.00   \n",
       "6            1.34          0.01             0.01            0.00   \n",
       "7            1.36          0.03             0.01            0.00   \n",
       "8            1.36          0.02             0.01            0.00   \n",
       "9            1.36          0.02             0.01            0.00   \n",
       "10           1.38          0.04             0.01            0.00   \n",
       "11           1.37          0.01             0.01            0.00   \n",
       "12           1.36          0.01             0.01            0.00   \n",
       "13           1.34          0.02             0.01            0.00   \n",
       "14           1.36          0.02             0.01            0.00   \n",
       "\n",
       "   param_max_depth             params  split0_test_score  split1_test_score  \\\n",
       "0               10  {'max_depth': 10}               0.81               0.71   \n",
       "1               13  {'max_depth': 13}               0.85               0.75   \n",
       "2               16  {'max_depth': 16}               0.84               0.76   \n",
       "3               19  {'max_depth': 19}               0.83               0.77   \n",
       "4               22  {'max_depth': 22}               0.82               0.76   \n",
       "5               25  {'max_depth': 25}               0.82               0.75   \n",
       "6               28  {'max_depth': 28}               0.82               0.76   \n",
       "7               31  {'max_depth': 31}               0.81               0.74   \n",
       "8               34  {'max_depth': 34}               0.81               0.74   \n",
       "9               37  {'max_depth': 37}               0.81               0.74   \n",
       "10              40  {'max_depth': 40}               0.82               0.73   \n",
       "11              43  {'max_depth': 43}               0.81               0.75   \n",
       "12              46  {'max_depth': 46}               0.81               0.75   \n",
       "13              49  {'max_depth': 49}               0.81               0.74   \n",
       "14              52  {'max_depth': 52}               0.81               0.74   \n",
       "\n",
       "    split2_test_score  split3_test_score  split4_test_score  mean_test_score  \\\n",
       "0                0.80               0.79               0.78             0.78   \n",
       "1                0.84               0.83               0.84             0.82   \n",
       "2                0.85               0.84               0.86             0.83   \n",
       "3                0.85               0.85               0.85             0.83   \n",
       "4                0.84               0.82               0.84             0.82   \n",
       "5                0.84               0.82               0.84             0.81   \n",
       "6                0.83               0.82               0.83             0.81   \n",
       "7                0.83               0.82               0.83             0.81   \n",
       "8                0.83               0.81               0.83             0.81   \n",
       "9                0.82               0.81               0.83             0.80   \n",
       "10               0.82               0.83               0.83             0.80   \n",
       "11               0.81               0.81               0.82             0.80   \n",
       "12               0.82               0.80               0.82             0.80   \n",
       "13               0.82               0.82               0.83             0.81   \n",
       "14               0.82               0.81               0.83             0.80   \n",
       "\n",
       "    std_test_score  rank_test_score  split0_train_score  split1_train_score  \\\n",
       "0             0.03               15                0.89                0.89   \n",
       "1             0.03                3                0.97                0.97   \n",
       "2             0.03                2                0.99                0.99   \n",
       "3             0.03                1                1.00                1.00   \n",
       "4             0.03                4                1.00                1.00   \n",
       "5             0.03                6                1.00                1.00   \n",
       "6             0.03                5                1.00                1.00   \n",
       "7             0.03                7                1.00                1.00   \n",
       "8             0.03                8                1.00                1.00   \n",
       "9             0.03               11                1.00                1.00   \n",
       "10            0.04               10                1.00                1.00   \n",
       "11            0.03               14                1.00                1.00   \n",
       "12            0.03               13                1.00                1.00   \n",
       "13            0.03                9                1.00                1.00   \n",
       "14            0.03               12                1.00                1.00   \n",
       "\n",
       "    split2_train_score  split3_train_score  split4_train_score  \\\n",
       "0                 0.89                0.87                0.89   \n",
       "1                 0.96                0.97                0.97   \n",
       "2                 0.99                0.99                0.99   \n",
       "3                 1.00                1.00                1.00   \n",
       "4                 1.00                1.00                1.00   \n",
       "5                 1.00                1.00                1.00   \n",
       "6                 1.00                1.00                1.00   \n",
       "7                 1.00                1.00                1.00   \n",
       "8                 1.00                1.00                1.00   \n",
       "9                 1.00                1.00                1.00   \n",
       "10                1.00                1.00                1.00   \n",
       "11                1.00                1.00                1.00   \n",
       "12                1.00                1.00                1.00   \n",
       "13                1.00                1.00                1.00   \n",
       "14                1.00                1.00                1.00   \n",
       "\n",
       "    mean_train_score  std_train_score  \n",
       "0               0.88             0.01  \n",
       "1               0.97             0.00  \n",
       "2               0.99             0.00  \n",
       "3               1.00             0.00  \n",
       "4               1.00             0.00  \n",
       "5               1.00             0.00  \n",
       "6               1.00             0.00  \n",
       "7               1.00             0.00  \n",
       "8               1.00             0.00  \n",
       "9               1.00             0.00  \n",
       "10              1.00             0.00  \n",
       "11              1.00             0.00  \n",
       "12              1.00             0.00  \n",
       "13              1.00             0.00  \n",
       "14              1.00             0.00  "
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.plot(scores[\"param_max_depth\"], \n",
    "         scores[\"mean_train_score\"], \n",
    "         label=\"training accuracy\")\n",
    "plt.plot(scores[\"param_max_depth\"], \n",
    "         scores[\"mean_test_score\"], \n",
    "         label=\"test accuracy\")\n",
    "plt.xlabel(\"max_depth\")\n",
    "plt.ylabel(\"Recall\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Classifier : \n",
      "-------------------------\n",
      "Classification report :  \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.88      0.93      8225\n",
      "           1       0.35      0.71      0.47       701\n",
      "\n",
      "   micro avg       0.87      0.87      0.87      8926\n",
      "   macro avg       0.66      0.80      0.70      8926\n",
      "weighted avg       0.92      0.87      0.89      8926\n",
      "\n",
      "Accuracy   Score :  0.8714989917096123\n",
      "Recall Score on train Set:  0.97214470012111\n",
      "Recall Score on test Set:  0.7132667617689016\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Support Vector Machine : \n",
      "-------------------------\n",
      "Classification report :  \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.78      0.87      8225\n",
      "           1       0.24      0.82      0.37       701\n",
      "\n",
      "   micro avg       0.78      0.78      0.78      8926\n",
      "   macro avg       0.61      0.80      0.62      8926\n",
      "weighted avg       0.92      0.78      0.83      8926\n",
      "\n",
      "Accuracy   Score :  0.7836656957203675\n",
      "Recall Score on train Set:  0.7484071402243168\n",
      "Recall Score on test Set:  0.8216833095577746\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance on train set:  0.7867937444052446\n",
      "Performance on test set:  0.7888730385164051 \n",
      "\n",
      "XGBooster algorithm : \n",
      "-------------------------\n",
      "Classification report :  \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.80      0.88      8225\n",
      "           1       0.25      0.79      0.39       701\n",
      "\n",
      "   micro avg       0.80      0.80      0.80      8926\n",
      "   macro avg       0.62      0.80      0.63      8926\n",
      "weighted avg       0.92      0.80      0.84      8926\n",
      "\n",
      "Accuracy   Score :  0.802375084024199\n",
      "Recall Score :  0.7888730385164051\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adaboost Classifier : \n",
      "-------------------------\n",
      "Classification report :  \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.78      0.87      8225\n",
      "           1       0.24      0.81      0.37       701\n",
      "\n",
      "   micro avg       0.78      0.78      0.78      8926\n",
      "   macro avg       0.61      0.79      0.62      8926\n",
      "weighted avg       0.92      0.78      0.83      8926\n",
      "\n",
      "Accuracy   Score :  0.7825453730674434\n",
      "Recall Score on train Set:  0.7678900531830867\n",
      "Recall Score on test Set:  0.8059914407988588\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
